{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithms vs. Sumulated Annealing \n",
    "### Regression Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Max Wiesner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 16/90 [05:17<1:06:24, 53.85s/it]"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from curveFitting import one_dimensional_curve_fitting_test\n",
    "from IPython.display import display, HTML\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "tests = [\n",
    "    [lambda x: 0.2*math.exp(x/4.0) -  math.sin(2*x), (-10.0, 10.0), 25],\n",
    "    [lambda x: math.sin(2*x) - math.cos(3*x-1) + 2*math.sin(x/2+1.0), (-15.0, 15.0), 60],\n",
    "    [lambda x: math.exp(math.sin(2*x)) - math.exp(math.cos(3*x)), (-15.0, 15.0), 60],\n",
    "    [lambda x: 0.05*x**2 - 0.5*x + 5.0 * math.sin(3*x) , (-15.0, 15.0), 60],\n",
    "    [lambda x: 0.05*x**2 - 0.5*math.sqrt(x) + 5.0 * math.sin(3*x) , (0.0, 15.0), 30]\n",
    "]\n",
    "\n",
    "each_test = 3\n",
    "i_std = 0.5\n",
    "p_std = 0.5\n",
    "GA_criteria = np.array([[i_std*1000, p_std*40], [i_std*500, p_std*80], [i_std*250, p_std*160]]).astype(int)\n",
    "SA_criteria = np.array([[i_std*10000, p_std*40], [i_std*5000, p_std*80], [i_std*2500, p_std*160]]).astype(int)\n",
    "\n",
    "results = []\n",
    "test_instances = [{'results': [[-float('inf')]*5 for i in range(3)],\n",
    "                   'all': [[0]*5 for i in range(3)],\n",
    "                   'conditions': criteria} for criteria in [GA_criteria, SA_criteria]]\n",
    "\n",
    "with tqdm(total = each_test*len(GA_criteria)*len(test_instances)*len(tests)) as pbar:\n",
    "    for iteration in range(each_test):\n",
    "        for curr_algorithm in test_instances:\n",
    "            for curr_condition_index in range(len(curr_algorithm['conditions'])):\n",
    "                for curr_test_index in range(len(tests)):\n",
    "                    all_data_results = one_dimensional_curve_fitting_test(tests[curr_test_index][0], tests[curr_test_index][1], \n",
    "                        tests[curr_test_index][2], curr_algorithm['conditions'][curr_condition_index][0], curr_algorithm['conditions'][curr_condition_index][1])\n",
    "                    \n",
    "                    if all_data_results[1] > curr_algorithm['results'][curr_condition_index][curr_test_index]:\n",
    "                        curr_algorithm['results'][curr_condition_index][curr_test_index] = all_data_results[1]\n",
    "                        curr_algorithm['all'][curr_condition_index][curr_test_index] = all_data_results\n",
    "                    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "css = \"\"\"\n",
    ".output {\n",
    "    flex-direction: row;\n",
    "}\n",
    "\"\"\"\n",
    "HTML('<style>{}</style>'.format(css))\n",
    "\n",
    "title_specs = {\n",
    "    'selector': 'caption',\n",
    "    'props': [\n",
    "        ('color', 'blue'),\n",
    "        ('font-size', '18px')\n",
    "    ]\n",
    "}\n",
    "\n",
    "def highlight_last_max(data, colormax='antiquewhite', colormaxlast='lightgreen'):\n",
    "\n",
    "    colormax_attr = f'background-color: {colormax}'\n",
    "    colormaxlast_attr = f'background-color: {colormaxlast}'\n",
    "    max_value = data.max()\n",
    "    is_max = [colormax_attr if v == max_value else '' for v in data]\n",
    "    is_max[len(data) - list(reversed(data)).index(max_value) -  1] = colormaxlast_attr\n",
    "    return is_max\n",
    "\n",
    "    \n",
    "def create_data_frames():\n",
    "    dfs = [None]*2\n",
    "    names = ['Genetic Algorithm', 'Simulated Annealing Algorithm']\n",
    "     \n",
    "    for ind in range(len(names)):\n",
    "        df = pd.DataFrame(np.array( [[test_instances[ind]['results'][i][j] for j in range(5)] for i in range(3)]), index = [f'{crit[0]}, {crit[1]}' for crit in GA_criteria], \n",
    "                                   columns = [f'Function {i}' for i in range(1, 6)])\n",
    "        \n",
    "        df.style.set_table_attributes(\"style='display:inline'\").set_caption(f'{names[ind]} - Regression Estimation')\n",
    "        df.loc['Fitness Avg by Function']= df.mean(numeric_only=True, axis=0)\n",
    "        df.loc[:,'Fitness Avg by Criteria'] = df.mean(numeric_only=True, axis=1)\n",
    "        pd.options.display.float_format = '{:,.3f}'.format        \n",
    "        df = df.rename_axis('Criteria: Num of Iterations, Population Size')\n",
    "        \n",
    "        df['Run Time Avg by Criteria'] = [np.mean([test_instances[0]['all'][i][j][3] for j in range(5)]) for i in range(3)] + [None]\n",
    "        df.loc['Run Time Avg by Function'] = [np.mean([test_instances[0]['all'][i][j][3] for i in range(3)]) for j in range(5)] + \\\n",
    "            [None, np.mean([np.mean([test_instances[0]['all'][i][j][3] for i in range(3)]) for j in range(5)])]\n",
    "        \n",
    "        df = df.style.apply(highlight_last_max, subset = pd.IndexSlice[[f'{crit[0]}, {crit[1]}' for crit in GA_criteria], [f'Function {i}' for i in range(1, 6)]], axis = 0) \\\n",
    "            .set_table_attributes(\"style='display:inline'\") \\\n",
    "            .set_caption(f'{names[ind]} - Regression Estimation') \\\n",
    "            .set_table_styles([title_specs]) \\\n",
    "            .apply(highlight_last_max, subset = pd.IndexSlice[\"Fitness Avg by Function\":\"Run Time Avg by Function\", \\\n",
    "                                            [f'Function {i}' for i in range(1, 6)]], axis = 1, colormaxlast = 'lightblue') \\\n",
    "            .apply(highlight_last_max, subset = pd.IndexSlice[ [f'{crit[0]}, {crit[1]}' for crit in GA_criteria], \\\n",
    "                                            ['Fitness Avg by Criteria', 'Run Time Avg by Criteria']], axis = 0, colormaxlast = 'lightblue') \\\n",
    "            .apply(highlight_last_max, subset = pd.IndexSlice[\"Fitness Avg by Function\", ['Fitness Avg by Criteria']], axis = 0, colormaxlast = '#ffcccb')  \\\n",
    "            .apply(highlight_last_max, subset = pd.IndexSlice[\"Run Time Avg by Function\", ['Run Time Avg by Criteria']], axis = 0, colormaxlast = '#ffcccb')  \n",
    "        dfs[ind] = df\n",
    "        \n",
    "    return dfs\n",
    "    \n",
    "dfs = create_data_frames()\n",
    "print('\\n')\n",
    "display(dfs[0])\n",
    "print('\\n\\n')\n",
    "display(dfs[1])\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_plot(data):\n",
    "    plt.figure(1)\n",
    "    x_values = [x_value for ([x_value], _) in data]\n",
    "    plt.plot(x_values, [y for (_,y) in data],'x')\n",
    "    test_xvalues = sorted([x for [x] in test_points])\n",
    "    result = [best_expr.eval({'x':x_value}) for x_value in test_xvalues ]\n",
    "    gTruth = [lambda_fun(x_value) for x_value in test_xvalues ]\n",
    "    plt.plot(test_xvalues, result, 'r-',label='ga_fit')\n",
    "    plt.plot(test_xvalues, gTruth, 'g-', label='ground-truth')\n",
    "    plt.legend()\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.figure(2)\n",
    "    plt.plot(range(len(stats)), [st for st in stats], 'b-')\n",
    "    plt.xlabel('Iters')\n",
    "    plt.ylabel('Max Fitness')\n",
    "    plt.plot(range(len(stats)), [(st[1] if st[1] > -100 else -100) for st in stats], 'r--')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a brief analysis of your results. Some questions to answer:\n",
    "- Which problem ran the fastest? Why do you think this is the case?\n",
    "- Which problem ended with the highest fitness? Why do you think this is the case?\n",
    "- How similar were the running times across the 5 repetitions?\n",
    "- How similar were the final fitness scores across the 5 repetitions?\n",
    "- Was there anything else interesting in your results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Your answer here.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe Your Implementation and Reflect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some questions to answer in your write-up:\n",
    "- What was your strategy to solve this problem?\n",
    "- How did you structure your `GASolver` class?\n",
    "- What other files or methods did you change?\n",
    "- What was the most difficult part of the project?\n",
    "- What was something surprising you found?\n",
    "\n",
    "Please provide some elaboration with your answers. When describing your implementation, remember that we have not watched you solve this problem so you will need to give more details than you think is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Your answer here.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going Above and Beyond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the extra changes you implemented. Give some details, perhaps a short paragraph for each major change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Your answer here.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the analysis you did and provide your results in the form of a figure or a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Your answer here.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflect on your work for this section. What was interesting, or what did you learn? A short paragraph here is fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Your answer here.`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
